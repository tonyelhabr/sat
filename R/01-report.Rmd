---
title: ""
author: "Tony"
date: "May 9, 2018"
output:
  html_document:
    toc: true
---

```{r setup, include = FALSE}
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
knitr::opts_chunk$set(
  # echo = TRUE,
  echo = FALSE,
  cache = TRUE,
  # include = FALSE,
  fig.align = "center",
  # s = "asis",
  fig.width = 7,
  fig.height = 7,
  # out.width = 7,
  # out.height = 7,
  warning = FALSE,
  message = FALSE
)
```

```{r config, include = FALSE}
config <-
  list(
    export_data = TRUE,
    dir_data = "data",
    export_viz = TRUE,
    dir_viz = "figs",
    download = FALSE
  )
```

## Introduction

I wanted to do a follow-up on my posts about Texas high school UIL academic competitions
where I evaluate the relationship between the school performance in those
competitions with school-wide SAT and ACT scores.
In my introduction to that series, I stated the following:
<i>
School-wide ... scores on state- and national-standardized 
tests (e.g. the Standardized [SAT](https://en.wikipedia.org/wiki/SAT))
certainly are the most common measure of academic strength,
but I think rankings by academic competitions may be more indicative.
</i>

In a sense, I implied that the academic UIL scores may not correspond
well, or at all, with standardized test scores. So let's set out to see what
we can prove (one way or the other).

## Data Collection

To my delight,
the [Texas Education Agency's website](https://tea.texas.gov) publishes
Texas high school SAT and [ACT](https://www.act.org/) scores for the years 2011 through 2015.
(For those who may not be familiar with these tests, which, strangely don't really
have non-abbreviated names, they are the two most popular standardized tests
used for college admission in the United States.) The task
of scraping from this source is a perfect
use-case for the super-handy `{xml2}` and `{rvest}` packages,
as well the well-knwon `{stringr}` and `{purrr}` packages in the `{tidyverse}`.

```{r packages}
library("tidyverse")
library("rlang")
library("teplot")
```

```{r scrape_tea}
urls_tea <-
  "https://tea.texas.gov/acctres/sat_act_index.html" %>%
  xml2::read_html() %>%
  rvest::html_nodes(xpath = "//tr //td //a") %>%
  rvest::html_attr("href") %>% 
  str_subset("^\\/acctres\\/[:alpha:]{3}_[Cc]ampus_[Dd]ata")
urls_tea
```

```{r create_path_dl_tea}
create_path_dl_tea <-
  function(url_suffix = NULL, dir = "data-raw", ext = "csv") {
    if(!dir.exists(dir)) {
       dir.create(dir)
    }
    url_suffix %>%
      str_remove_all("acctres|\\/") %>% 
      paste0(".", ext) %>% 
      file.path(dir, .)
  }
```

```{r urls_tea_dl, eval = FALSE}
# NOTE(s):
# + `urls_tea_dl` is actually the same as `url_tea` because `purrr::walk()` returns its first argument.
# + `mode = "wb"` is important! Otherwise, the downloaded files have empty lines every other line
# (due to the way that CR and LFs are handled.
urls_tea_dl <-
  urls_tea %>%
  walk(
    ~download.file(
      url = paste0("https://tea.texas.gov/", .x),
      destfile = create_path_dl_tea(url_suffix = .x),
      mode = "wb"
    )
  )
```

Although the reader may not care to see the gory details of the data cleansing,
I'll show the code anyways for those few who may be interested. I know that I usually
pick up one or two things that I'd never seen before when reviewing others'
code for data cleaning (and other data management tasks).

```{r schools_tea, results = "hide"}
schools_tea <-
  urls_tea %>%
  create_path_dl_tea() %>%
  tibble(path = .) %>%
  mutate(
    test = stringr::str_extract(path, "([Ss][Aa][Tt])|([Aa][Cc][Tt])") %>% str_to_upper(),
    year = stringr::str_extract(path, "[:digit:]+") %>% as.integer()
  ) %>%
  mutate(contents =
           purrr::map2(path, test,
                       # ~import_tea_data(.x, .y)
                       ~ {
                         .x %>%
                           readr::read_csv() %>%
                           rename_all(funs(tolower)) %>%
                           filter(group == "All Students") %>%
                           select(
                             matches(
                               "name$|math|reading|writing|total|english|science|compos"
                             )
                           )
                       })) %>%
  unnest() %>%
  select(-path) %>%
  mutate_at(vars(total), funs(ifelse(test == "ACT", compos, .))) %>% 
  select(-compos) %>% 
  select(-total, everything(), total) %>% 
  rename(school = campname,
         district = distname,
         county = cntyname,
         city = regnname) %>%
  mutate_if(is.character, funs(str_replace_all(., "=|\"", ""))) %>%
  mutate_at(vars(matches("school|district|city|county")), funs(toupper)) %>% 
  mutate_at(vars(county), funs(str_remove_all(., "\\s+COUNTY"))) %>%
  mutate_at(vars(school), funs(str_remove_all(., "[H]\\s*[S]$") %>% str_trim())) %>%
  # NOTE: This is (try to) to resolve duplicates in raw data.
  # group_by_at(vars(matches("test|year|school|district|county|city"))) %>% 
  # summarise_all(funs(max(., na.rm = TRUE))) %>% 
  # ungroup() %>% 
  arrange(test, year, school)
schools_tea
```

```{r schools_tea_debug, include = FALSE, eval = FALSE}
# Debugging...
schools_tea
schools_tea %>%
  count(test, year, is.na(school), sort = TRUE)
schools_tea %>%
  count(test, year, school, city, sort = TRUE) %>% 
  count(n, sort = TRUE)
schools_tea %>%
  count(test, year, school, city, sort = TRUE) %>% 
  filter(n > 1)
```

```{r schools_tea_export, include = FALSE}
teproj::export_ext_csv(
  schools_tea,
  export = config$export_data,
  dir = config$dir_data
)
```

```{r schools_tea_import, include = FALSE}
schools_tea <-
  teproj::import_ext_csv(
    schools_tea,
    dir = config$dir_data
  )
```

```{r schools_tea_show, echo = FALSE}
schools_tea %>% 
  teproj::create_kable()
```

### Data Exploration

First, before evaluating the primary concern at hand--the relationship between
the academic UIL scores (accessible in data that I collected
and cleaned for my series of posts analyzing the UIL data)
and the SAT/ACT scores (available in the `schools_tea` data
created above)--I first want to verify that
there is some non-trivial relationship among the scores for a given school on a given
test across years. (I would be suprised if this were not shown to be true.)

```{r schools_tea_corss_byyear, results = "hide"}
schools_tea_cors_byyear <-
  schools_tea %>%
  distinct(test, year, school, .keep_all = TRUE) %>%
  filter(!is.na(total)) %>%
  unite(test_school, test, school) %>%
  widyr::pairwise_cor(
    feature = test_school,
    item = year,
    value = total
  ) %>% 
  rename(year1 = item1, year2 = item2, cor = correlation)
schools_tea_cors_byyear %>% 
  filter(year1 <= year2)
```

```{r schools_tea_corss_byyear_show, echo = FALSE}
schools_tea_cors_byyear %>% 
  filter(year1 <= year2) %>% 
  teproj::create_kable()
```


```{r viz_schools_tea_cors, echo = FALSE}
visualize_cors_byyear <-
  function(data = NULL,
           alpha = 0.7,
           n_digits = 2,
           ...) {
    data %>%
      ggplot(aes(x = year1, y = year2, fill = cor)) +
      geom_tile(alpha = alpha) +
      geom_text(aes(label = round(cor, n_digits)), size = 5) +
      scale_fill_gradient2(...) +
      scale_x_continuous(breaks = scales::pretty_breaks()) +
      scale_y_continuous(breaks = scales::pretty_breaks()) +
      # scale_fill_viridis_c(option = "C", direction = -1, limits = limits) +
      teplot::theme_te_tile(base_size = 12) +
      coord_equal() +
      theme(legend.position = "none",
            axis.text = element_text(size = 12)) +
      labs(x = NULL,
           y = NULL)
  }
viz_schools_tea_cors_byyear <-
  schools_tea_cors_byyear %>%
  filter(year2 <= year1) %>% 
  visualize_cors_byyear(
    alpha = 0.7,
    n_digits = 2,
    low = "white",
    mid = "yellow",
    high = "red",
    limits = c(0, 0.9),
    midpoint = 0.45
  ) +
  labs(title = str_wrap(
    "Correlation of SAT/ACT Scores Among Years for Texas High Schools",
    80
  ))
viz_schools_tea_cors_byyear
```

As expected, there is some storng correlations among the years for school-wide scores
on these tests.

```{r viz_schools_tea_cors_export, include = FALSE}
teproj::export_ext_png(
  viz_schools_tea_cors_byyear,
  export = config$export_viz,
  dir = config$dir_viz,
  units = "in",
  height = 8,
  width = 8
)
```

Ok, now let's bring in the "cleaned" school data (`schools_uil`) that I collected
and cleaned my UIL analysis.

```{r schools_uil, results = "hide"}
schools_uil <-
  file.path("data", "schools_uil.csv") %>% 
  readr::read_csv()
schools_uil
```

```{r schools_uil_show, echo = FALSE}
schools_uil %>% 
  teproj::create_kable()
```

Now let's review this data set to see if year-to-year correlations also exist with it.

Importantly, some choice about how to quantify performance needs to be made.
As I discussed in my long-form series of posts exploring the UIL academic data,
the evaluation of performance is somewhat subjective. Should we use
number of times a school advanced to the next level of competition in a given year?
(Note that there are three competition levels--`District`, `Region`, and `State`.)
What about the number the number of other schools it "defeated" in head-to-head competitions?
In that separate analysis, I made the choice to use the percentile rank (`prnk`) of the school's placings
across all competition levels for a given competition type (`comp`). 
I beleive this measure bests represent
a school's quality of performance (where a higher value indicates better performance).
As I stated there when explaining
my choice to use percent rank for identifying "dominant" individual",
<i>
"I choose to use percent rank--which is a always a value between 0 and 1--because
it inherently accounts for the
wide range of number of competitors across all competitions. 
(For this context, a percent rank of 1 corresponds to the highest score in a given
competition, and, conversely,
a value of 0 corresponds to the lowest score.)"
</i>

Aside from this important choice regarding performance evaluation in academic UIL competitions,
note that I treat the competition type (`comp`) in `schools_uil`
as analogous to the `test` variable 
indicating SAT or ACT score in the `schools_tea` data set.
For those who have not read through my UIL analysis, note that scores for
five different competition types
was collected--`Calculator Applications`, `Computer Science`, `Mathematics`, `Number Sense`, and `Science`.


```{r schools_uil_cors_byyear, results = "hide"}
schools_uil_cors_byyear <-
  schools_uil %>% 
  select(year, school, city, comp, prnk) %>% 
  group_by(year, school, city, comp) %>% 
  summarise(prnk_sum = sum(prnk, na.rm = TRUE)) %>%
  ungroup() %>% 
  unite(comp_school, comp, school) %>%
  widyr::pairwise_cor(
    feature = comp_school,
    item = year,
    value = prnk_sum
  ) %>% 
  rename(year1 = item1, year2 = item2, cor = correlation)

schools_uil_cors_byyear %>% 
  filter(year1 <= year2) 
```

```{r schools_uil_cors_byyear, echo = FALSE}
schools_uil_cors_byyear %>% 
  filter(year1 <= year2) %>% 
  teproj::create_kable()
```

```{r schools_uil_cors_byyear, echo = FALSE}
viz_schools_uil_cors_byyear <-
  schools_uil_cors_byyear %>% 
  filter(year2 <= year1) %>% 
  visualize_cors_byyear(
    alpha = 0.7,
    n_digits = 1,
    low = "white",
    mid = "yellow",
    high = "red",
    limits = c(0, 0.9),
    midpoint = 0.45
  ) +
  labs(title = str_wrap(
    "Correlation of UIL Academic Scores Among Years for Texas High Schools", 80)
  )
viz_schools_uil_cors_byyear
```

We can see that correlations among years do exist, as we would expect.
The strength of the correlations decrease for years that are farther apart,
which is also what we might expect.

### Aside: Fuzzy Joining

An important thing to keep in mind is that
the acadmeic UIL data was scraped from a different website--https://www.hpscience.net/ (which 
was the only site that I found to have the academic competition scores)--than
that used to collect the SAT and ACT scores here. 

In its raw form,
the UIL data is much "more unclean" than the data from the TEA website, and some/many
of the names are inconsistent. In fact, the rigor involved in cleaning the UIL data
obliged be to completely hide it from the reader in my write-ups on the topic.
Nonetheless, I was able to eliminate much of the "self-inconsistency" of the UIL data
and create a suitable data set to use as one of the basis for that long-form analysis.

However, given this context--in which I am comparing data from two
different data sources--the reality is that there are more than a few differences in the
names of schools, so joining the data from the two different sources is tricky. 
To aid in my experimentation
with "fuzzy joining", I created a function--`join_fuzzily()`-- to serve as
a wrapper for the `stringdist_*_join()` functions provided by the `{fuzzyjoin}` package.
With this function, I was able to evaluate different values for `max_dist` and
different join columns to
make a judgement regarding the quality of joins--primarily via counts
of joined and unjoined rows using the `summarise_join_stats()` function from my
personal `{tetidy}` package--to make a decision on how I should join the UIL and
SAT/ACT school data. [^dry]

[^dry]:
Check out [my post on the "DRY" principle and its application to `R` packages]().

What follows is the results of some of my experimentation.

```{r join_fuzzily}
join_fuzzily <-
  function(x = NULL,
           y = NULL,
           how = "inner",
           max_dist = 0,
           cols_join = "school",
           copy = FALSE,
           suffix_x = "_x",
           suffix_y = "_y") {

    f <- sprintf("fuzzyjoin::stringdist_%s_join", how)

    ret <-
      teproj::do_call_with(f, list(x = x, y = y, by = cols_join, max_dist = max_dist))

    ret <-
      ret %>%
      rename_at(vars(ends_with(".x")), funs(gsub("\\.x", suffix_x, .))) %>%
      rename_at(vars(ends_with(".y")), funs(gsub("\\.y", suffix_y, .)))

    if(copy) {
      cols_join_y <- quo_name(paste0(cols_join, suffix_y))
      ret <-
        ret %>%
        left_join(y %>% mutate(!!!sym(cols_join_y) := !!!sym(cols_join)), by = cols_join)
    }
    ret
  }
```

```{r summ_schools_join_fuzzy, results = "hide"}
schools_uil_distinct <-
  schools_uil %>%
  distinct(school, city)
```

```{r summ_schools_join_fuzzy_1, results = "hide"}
summ_schools_join_fuzzy_1 <-
  schools_tea %>%
  join_fuzzily(
    schools_uil_distinct,
    how = "full",
    max_dist = 0,
    cols_join = c("school"),
    suffix_x = "_tea",
    suffix_y = "_uil"
  ) %>%
  tetidy::summarise_join_stats(school_uil, school_tea) %>% 
  select(-x, -y) %>% 
  gather(metric, value)
summ_schools_join_fuzzy_1
```

```{r summ_schools_join_fuzzy_1_show, echo = FALSE}
summ_schools_join_fuzzy_1 %>% 
  teproj::create_kable()
```

```{r summ_schools_join_fuzzy_2, results = "hide"}
# NOTE: Use a full join to get more informative output from `tetidy::summarise_join_stats()`.
summ_schools_join_fuzzy_2 <-
  schools_tea %>%
  unite(school_city, school, city, remove = FALSE) %>%
  join_fuzzily(
    schools_uil_distinct %>%
      unite(school_city, school, city, remove = FALSE),
    how = "full",
    # how = "left",
    max_dist = 0,
    cols_join = c("school_city"),
    suffix_x = "_tea",
    suffix_y = "_uil"
  ) %>%
  tetidy::summarise_join_stats(school_city_uil, school_city_tea) %>% 
  select(-x, -y) %>% 
  gather(metric, value)
summ_schools_join_fuzzy_2
```

```{r summ_schools_join_fuzzy_2_show, echo = FALSE}
summ_schools_join_fuzzy_2 %>% 
  teproj::create_kable()
```

```{r schools_join_old, results = "hide", include = FALSE, eval = FALSE}
schools_join <-
  schools_tea %>%
  unite(school_city, school, city, remove = FALSE) %>%
  join_fuzzily(
    schools_uil_distinct %>%
      unite(school_city, school, city, remove = FALSE),
    how = "inner",
    max_dist = 0,
    cols_join = c("school_city"),
    suffix_x = "_tea",
    suffix_y = "_uil"
  ) %>% 
  select(-matches("school_city")) %>% 
  # NOTE: Do this to remove some rows that are recorded twice in the original data.
  # Duplicates may be due to same school-city combination for two different districts.
  group_by_at(vars(matches("test|year|school|county|city"))) %>% 
  summarise_all(funs(max(., na.rm = TRUE))) %>% 
  ungroup() %>% 
  mutate_at(vars(matches("math|reading|writing|english|science|total")),
            funs(if_else(is.infinite(.), NA_real_, .)))
schools_join
```

After some further "offline" experimentation, 
I came to conclusion that none of these fuzzy join
attempts was satisfiable.
Thus, I decided that I would simply combine the two data sets 
with an `inner_join()` on
`school` and  `city` (as well as `year`, to make sure that
school scores match up properly) with the understanding that many schools end up being excluded
due to imperfect matching. With data

### Relationship between Academic UIL Performance and SAT/ACT scores.

So, at this point, having decided how to join the data,
I have set myself up to do that which I set out to do--evaluate
the relationship between the academic UIL competition scores and the national SAT/ACT scores.

In order to put the two sets of data on "equal grounds",
I only evaluate math scores.
In particular, I filter `comp` in the UIL data to just the
mathematically-based competitions--`Calculator Applications`,
`Mathematics`, and `Number Sense`--excluding `Science` and `Computer Science`. And,
for the SAT/ACT data, I select only the `math` score, which
is available fore both tests, excluding
the `total` and `reading` scores also available for each and the 
`writing`, `english`, and `science` scores available for one or the other.
(Perhaps the ACT's `science` score could be compared to the `Science` UIL scores,
but I choose not to do so here.)

```{r schools_uil_stats, results = "hide"}
schools_uil_stats <-
  schools_uil %>%
  filter(str_detect(comp, "Calculator|Math|Number")) %>%
  group_by(year, school, city) %>% 
  summarise(prnk_sum = sum(prnk, na.rm = TRUE)) %>%
  ungroup() %>% 
  # NOTE: "Renormalize" `prnk_sum`.
  mutate(math_prnk = percent_rank(prnk_sum)) %>% 
  select(-prnk_sum)
schools_uil_stats
```

```{r schools_uil_stats_show, echo = FALSE}
schools_uil_stats %>% 
  teproj::create_kable()
```

```{r schools_tea_stats, results = "hide"}
schools_tea_stats <-
  schools_tea %>%
  select(test, year, school, city, math) %>%
  filter(!is.na(math)) %>% 
  group_by(test) %>% 
  mutate(math_prnk = percent_rank(math)) %>%
  ungroup() %>% 
  group_by(year, school, city) %>% 
  summarise_at(vars(math_prnk), funs(mean(., na.rm = TRUE))) %>% 
  ungroup()
schools_tea_stats
```

```{r schools_tea_stats_show, echo = FALSE}
schools_tea_stats %>% 
  teproj::create_kable()
```

```{r schools_join_prnks, results = "hide"}
schools_join_prnks <-
  schools_tea_stats %>%
  rename_at(vars(matches("^math")), funs(paste0("tea_", .))) %>% 
  inner_join(schools_uil_stats %>% 
             rename_at(vars(matches("^math")), funs(paste0("uil_", .))),
           by = c("year", "school", "city")) %>%
  select(year, school, city, matches("math"))
schools_join_prnks
```

```{r schools_join_prnks_show, echo = FALSE}
schools_join_prnks %>% 
  teproj::create_kable()
```

```{r schools_join_prnks_export, include = FALSE}
teproj::export_ext_csv(
  schools_join_prnks,
  export = config$export_data,
  dir = config$dir_data
)
```

```{r schools_join_prnks_import, include = FALSE}
schools_join_prnks <-
  teproj::import_ext_csv(
    schools_join_prnks,
    dir = config$dir_data
  )
```

```{r schools_join_prnks_corrs}
schools_join_prnks_corrs <-
  schools_join_prnks %>%
  select(-year) %>% 
  select_if(is.numeric) %>%
  corrr::correlate()
schools_join_prnks_corrs
```

```{r}
cor <-
  schools_join_prnks_corrs %>% 
  gather(cor, value, -rowname) %>% 
  filter(!is.na(value)) %>% 
  distinct(value) %>% 
  pull(value)
```


So, this 

Note that the correlations in the joined data are 
~~not as high among the TEA (i.e. the SAT/ACT) data as they are in the original, unjoined data.~~

```{r schools_tea_prnks_tidy}
schools_tea_prnks_tidy <-
  schools_join_prnks %>%
  unite(school_city, school, city) %>% 
  gather(metric, value, matches("prnk"))
```

```{r pairwise_cor_f}
pairwise_cor_f <-
  function(data = NULL, which = c("tea", "uil")) {
    which <- match.arg(which)
    data %>%
      filter(metric %>% str_detect(which)) %>% 
      filter_at(vars(value), all_vars(!is.nan(.))) %>% 
      widyr::pairwise_cor(
        feature = school_city,
        item = year,
        value = value
      ) %>% 
      rename(year1 = item1, year2 = item2, cor = correlation) %>% 
      mutate(source = which)
  }
```

```{r schools_prnks_cors_byyear}
schools_prnks_cors_byyear <-
  bind_rows(
    schools_tea_prnks_tidy %>% 
      pairwise_cor_f("tea"),
    schools_tea_prnks_tidy %>% 
      pairwise_cor_f("uil")
  )
```

```{r schools_prnks_cors_byyear_wide, results = "hide"}
schools_prnks_cors_byyear_wide <-
  schools_prnks_cors_byyear %>% 
  filter(year1 <= year2) %>% 
  unite(year_pair, year1, year2) %>% 
  spread(source, cor)
schools_prnks_cors_byyear_wide
```

```{r schools_tea_prnks_cors_byyear_wide_show, echo = FALSE}
schools_prnks_cors_byyear_wide %>% 
  teproj::create_kable()
```

```{r viz_schools_cors_byyear, echo = FALSE}
viz_schools_cors_byyear <-
  schools_prnks_cors_byyear %>% 
  visualize_cors_byyear(
    alpha = 0.7,
    n_digits = 2,
    low = "cyan",
    high = "red",
    limits = c(0.5, 0.9)
  ) +
  labs(title = str_wrap(
    "Correlation of UIL Academic Scores and SAT/ACT Scores Among Years for Texas High Schools", 80)
  ) +
  facet_wrap( ~ source)
viz_schools_cors_byyear
```


```{r schools_tea_eda, include = FALSE, eval = FALSE}
# ## Bonus Data Exploration
# 
# As a final "aside" to the focus of this post, I thought it would be interesting
# (maybe only to me) to compare the SAT and ACT scores of my 
# high school--`SAMUEL CLEMENS` in the TEA data--with our primary rival--`BYRON P STEELE II`.
# (After all, I have made the effort to extract and clean this data, so I would
# be foolish not to explore any questions that I have in mind.)
# schools_tea %>%
#   select(test, year, school, total) %>%
#   distinct(test, year, school, .keep_all = TRUE) %>%
#   filter(str_detect(school, "CLEMENS|STEELE II")) %>%
#   spread(year, total)
```

Even though their football team may have been better than ours while I was attending
high school--which is a big deal in Texas--I can say that our school 
was better (marginally) according to a simple comparison of scores on these tests.
That may not be saying a lot to someone with no ties to this setting, but
it sparks a bit of pride in me!

## Conclusion

So, after doing some
more scraping, fuzzy joining, and basic statistics (correlation), I have a strong
case to make that
my initial inclination is correct--there is no significant relationship between
Texas high school academic competition scores and standardized test scores (for math).

